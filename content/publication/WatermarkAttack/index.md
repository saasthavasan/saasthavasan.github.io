---
title: 'Invisible Image Watermarks Are Provably Removable Using Generative AI'

# Authors
authors:
  - Xuandong Zhao
  - Kexun Zhang
  - Zihao Su
  - admin
  - Ilya Grishchenko
  - Christopher Kruegel
  - Giovanni Vigna
  - Yu-Xiang Wang
  - Lei Li

date: '2024-11-08T00:00:00Z'
publishDate: '2024-11-11T00:00:00Z'
doi: ''

# Publication type
publication_types:
  - paper-conference

# Publication details
publication: The 38th Annual Conference on Neural Information Processing Systems
publication_short: In NeurIPS 2024

# Abstract
abstract: >
  Invisible watermarks safeguard imagesâ€™ copyrights by embedding hidden messages
  only detectable by owners. They also prevent people from misusing images,
  especially those generated by AI models. We propose a family of regeneration
  attacks to remove these invisible watermarks. The proposed attack method first
  adds random noise to an image to destroy the watermark and then reconstructs the
  image. This approach is flexible and can be instantiated with many existing image-
  denoising algorithms and pre-trained generative models such as diffusion models.
  Through formal proofs and extensive empirical evaluations, we demonstrate that
  pixel-level invisible watermarks are vulnerable to this regeneration attack. Our
  results reveal that, across four different pixel-level watermarking schemes, the
  proposed method consistently achieves superior performance compared to existing
  attack techniques, with lower detection rates and higher image quality. However,
  watermarks that keep the image semantically similar can be an alternative defense
  against our attacks. Our finding underscores the need for a shift in research/industry
  emphasis from invisible watermarks to semantic-preserving watermarks. Code is
  available at [GitHub](https://github.com/XuandongZhao/WatermarkAttacker).

# Summary
summary: >
  Image watermarks embed hidden messages that are only detectable by the owners, 
  preventing misuse of images, especially those generated by AI models. In this paper 
  we introduce a family of regeneration attacks to remove these invisible watermarks. 
  By adding random noise to an image and then reconstructing it, this approach 
  effectively eliminates watermarks. The study highlights the vulnerability of all 
  invisible watermarks to this proposed attack, emphasizing the need for a shift 
  toward semantically similar watermarking methods.

# Tags
tags:
  - Image Watermarking
  - Generative AI
  - Adversarial Techniques
  - AI Security

# Featured options
featured: false

# Custom links
url_source: 'https://github.com/XuandongZhao/WatermarkAttacker'

# Associated projects (optional)
projects: []

# Slides (optional)
slides: ''
---
